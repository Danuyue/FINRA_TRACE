{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Model Analysis\n",
    "\n",
    "Todo: 1. industry : cusip to naics mapping 2. Topic evloution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from compute_topic import *\n",
    "from manage_path import *\n",
    "from topic_model_analysis import *\n",
    "\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True) \n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import datetime\n",
    "import plotly.plotly as py\n",
    "\n",
    "programmers = ['Alex','Nicole','Sara','Etienne','Chelsea','Jody','Marianne']\n",
    "\n",
    "base = datetime.datetime.today()\n",
    "date_list = [base - datetime.timedelta(days=x) for x in range(0, 180)]\n",
    "\n",
    "z = []\n",
    "\n",
    "for prgmr in programmers:\n",
    "    new_row = []\n",
    "    for date in date_list:\n",
    "        new_row.append( np.random.poisson() )\n",
    "    z.append(list(new_row))\n",
    "\n",
    "data = [\n",
    "    go.Heatmap(\n",
    "        z=z,\n",
    "        x=date_list,\n",
    "        y=programmers,\n",
    "        colorscale='Viridis',\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='GitHub commits per day',\n",
    "    xaxis = dict(ticks='', nticks=36),\n",
    "    yaxis = dict(ticks='' )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "plotly.offline.iplot(fig, filename='datetime-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Evolution\n",
    "1. Dc_v1: 1 document for buy and sell, per dealer, per day.\n",
    "2. Dc_v2: 1 document for buy and 1 document for sell, per dealer, per day.\n",
    "3. Dc_v3: Either DC_v1 or DC_v2 without the 2 (4) documents representing the Source_seller and Source_buyer.\n",
    "4. Tc_v1: 1 document for (buyer,seller,year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_directory = get_result_directory()\n",
    "topic = pd.read_csv(result_directory/'Dc_v1_250topics.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_item(document,position):\n",
    "    return str(document).split(',')[position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_document_item_vectorize = np.vectorize(get_document_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic['dealer'] = get_document_item_vectorize(topic.index,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic.index = pd.to_datetime(get_document_item_vectorize(topic.index,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = topic.groupby([\"dealer\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [go.Heatmap( z=count_matrix.values.tolist(), colorscale='Viridis')]\n",
    "plotly.offline.iplot(data, filename='pandas-heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Terms Distribution\n",
    "Below is the topic terms ditrutbution demo. Since we already got Document X Topics, we want to have a Topic X Terms too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('Tc_v1',250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_terms_distribution = pd.DataFrame(model.get_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_terms_distribution.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Industy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = get_pickle_directory() / 'TRACE2014_jinming.pkl'\n",
    "data = pd.read_pickle(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have {} rows of data\".format(data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_NAICS_Code(NAICS_Code):\n",
    "    \"Fix the problem that FISD omits 0 if NAICS_Code ends with 0\"\n",
    "    if len(str(NAICS_Code))==5:\n",
    "        NAICS_Code = NAICS_Code+'0'\n",
    "    return NAICS_Code\n",
    "fix_NAICS_Code_vectorize = np.vectorize(fix_NAICS_Code)\n",
    "data['NAICS_CODE'] = fix_NAICS_Code_vectorize(data['NAICS_CODE'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['BOND_SYM_ID', 'INDUSTRY_GROUP', 'INDUSTRY_CODE', 'PARENT_ID', 'NAICS_CODE','SIC_CODE']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['INDUSTRY_CODE'].value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the NAICS_code lookup table\n",
    "NAICS_code_path = get_dataset_directory() / 'NAICS_Code_Lookup.csv'\n",
    "NAICS_code = pd.read_csv(NAICS_code_path,dtype={'Code':str,'Description':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by BOND_SYM_ID and NAICS_CODE of \n",
    "NAICS_CODE_count = data['NAICS_CODE'].value_counts()\n",
    "# Series to DataFrame\n",
    "NAICS_CODE_count = NAICS_CODE_count.to_frame(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS_code_total = NAICS_code.merge(NAICS_CODE_count,left_on='Code',right_index=True).sort_values(by=\"count\",ascending=False)\n",
    "NAICS_code_total['percentage'] = NAICS_code_total['count']/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS_code_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(NAICS_code.merge(NAICS_CODE_count,left_on='Code',right_index=True).sort_values(by=\"count\",ascending=False)['count']/data.shape[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(by=['NAICS_CODE'])['BOND_SYM_ID'].nunique().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(by=['BOND_SYM_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bond_X_Industry = data.drop_duplicates(['BOND_SYM_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bond_X_Industry.sort_values(by=['BOND_SYM_ID']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "def convergence_likelyhood(model_name,num_topics):\n",
    "    p = re.compile(\"(-*\\d+\\.\\d+) per-word .* (\\d+\\.\\d+) perplexity\")\n",
    "    matches = [p.findall(l) for l in open('../LDAModel/{}_{}topics.log.txt'.format(model_name,num_topics))]\n",
    "    matches = [m for m in matches if len(m) > 0]\n",
    "    tuples = [t[0] for t in matches]\n",
    "    perplexity = [float(t[1]) for t in tuples]\n",
    "    liklihood = [float(t[0]) for t in tuples]\n",
    "    iter = list(range(0,len(tuples)*10,10))\n",
    "    plt.plot(iter,liklihood,c=\"black\")\n",
    "    plt.ylabel(\"log liklihood\")\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.title(\"Topic Model Convergence\")\n",
    "    plt.grid()\n",
    "    plt.savefig(\"{}_{}topics.pdf\".format(model_name,num_topics))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convergence_likelyhood(\"matrix_1\",250)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
