{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Model Analysis\n",
    "\n",
    "Todo: 1. industry : cusip to naics mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "import gensim\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "from compute_topic import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Topic Distribution\n",
    "Below, we will get top three topics per document with minimum probability threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# The model with model_name we want to load\n",
    "def load_model(model_name,topics):\n",
    "    current_path = os.getcwd()\n",
    "    current_path = Path(current_path)\n",
    "    topic_name =\"_{}topics\".format(topics)\n",
    "    file_name = model_name + topic_name\n",
    "    load_path = current_path.parents[0] / \"./LDAModel/{}/{}\".format(file_name,file_name)\n",
    "    load_path = str(load_path)\n",
    "    lda = gensim.models.ldamulticore.LdaMulticore.load(load_path)\n",
    "    return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading corpus...\n",
      "corpus successfully loaded!!\n",
      "MmCorpus(98304 documents, 12078 features, 4072730 non-zero entries)\n",
      "loading id2word ...\n",
      "id2word loaded!!\n"
     ]
    }
   ],
   "source": [
    "model_name = \"matrix_1\"\n",
    "from gensim.corpora import Dictionary\n",
    "corpus = load_corpus(model_name)\n",
    "id2word = load_id2word(model_name)\n",
    "dictionary = Dictionary.from_corpus(corpus,id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data TRACE2014_jinming...\n",
      "Getting data fromC:\\Users\\raymo\\UMD\\Research\\FINRA_TRACE\\Data\\Pickle\\TRACE2014_jinming...\n",
      "Data getting success!\n",
      "computing matrix_1 ......\n",
      "computing matrix_1 done!\n"
     ]
    }
   ],
   "source": [
    "# compute matrix to get for later creating data frame\n",
    "matrix_1 = compute_matrix1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_topic_distribution(matrix_object,model_name,topics,minimum_probability=0.10):\n",
    "    model = load_model(model_name,topics)\n",
    "    # minimum_probability is our threshold\n",
    "    document_topics = model.get_document_topics(corpus,minimum_probability=minimum_probability)\n",
    "    # convert document_topics, which is a gesim corpus, to numpy array\n",
    "    document_topic_distribution_numpy = gensim.matutils.corpus2dense(document_topics,num_terms=int(topics))\n",
    "    # need to transpose it because gensim represents documents on columns token on index\n",
    "    document_topic_distribution_numpy = np.transpose(document_topic_distribution_numpy)\n",
    "    # combine document_topic_distribution with index from matrix and columns represents gensim topics\n",
    "    document_topic_distribution_pandas = pd.DataFrame(data=document_topic_distribution_numpy,index=matrix_1.index,columns=np.arange(int(topics)))\n",
    "    # Only get the top three topics per document\n",
    "    document_topic_distribution_pandas = document_topic_distribution_pandas[document_topic_distribution_pandas.rank(axis=1,method='max',ascending=False) <= 3]\n",
    "    # Save the dataframe to csv\n",
    "    document_topic_distribution_pandas.to_csv('../Results/{}_{}topics.csv'.format(model_name,topics))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "document_topic_distribution(matrix_1,model_name=model_name,topics = \"150\")\n",
    "document_topic_distribution(matrix_1,model_name=model_name,topics = \"500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "def convergence_likelyhood(model_name,num_topics):\n",
    "    p = re.compile(\"(-*\\d+\\.\\d+) per-word .* (\\d+\\.\\d+) perplexity\")\n",
    "    matches = [p.findall(l) for l in open('../LDAModel/{}_{}topics.log.txt'.format(model_name,num_topics))]\n",
    "    matches = [m for m in matches if len(m) > 0]\n",
    "    tuples = [t[0] for t in matches]\n",
    "    perplexity = [float(t[1]) for t in tuples]\n",
    "    liklihood = [float(t[0]) for t in tuples]\n",
    "    iter = list(range(0,len(tuples)*10,10))\n",
    "    plt.plot(iter,liklihood,c=\"black\")\n",
    "    plt.ylabel(\"log liklihood\")\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.title(\"Topic Model Convergence\")\n",
    "    plt.grid()\n",
    "    plt.savefig(\"{}_{}topics.pdf\".format(model_name,num_topics))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convergence_likelyhood(\"matrix_1\",250)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
